{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fileinput\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import h2o\n",
    "from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "\n",
    "# Names of countries are not named consitently, it takes a lot of time to change all those names, for now use a \n",
    "# converter dictionary. If spare time, I'll change it. TODO.\n",
    "landNameConverter = {\n",
    "    \"United KingdomUK\": \"United Kingdom\",\n",
    "    \"United Kingdom\": \"United KingdomUK\",\n",
    "    \"SerbiaMontenegro\": \"Serbia and Montenegro\",\n",
    "    \"Serbia and Montenegro\": \"SerbiaMontenegro\",\n",
    "    \"BosniaHerzegovina\": \"Bosnia and Herzegovina\",\n",
    "    \"Bosnia and Herzegovina\": \"BosniaHerzegovina\",\n",
    "    \"North Macedonia\": \"North MacedoniaNorth MacedoniaN\",\n",
    "    \"North MacedoniaNorth MacedoniaN\": \"North Macedonia\",\n",
    "    \"Albania\": \"Albania\",\n",
    "\"Andorra\": \"Andorra\",\n",
    "\"Armenia\": \"Armenia\",\n",
    "\"Australia\": \"Australia\",\n",
    "\"Austria\": \"Austria\",\n",
    "\"Azerbaijan\": \"Azerbaijan\",\n",
    "\"Belarus\": \"Belarus\",\n",
    "\"Belgium\": \"Belgium\",\n",
    "\"Bulgaria\": \"Bulgaria\",\n",
    "\"Croatia\": \"Croatia\",\n",
    "\"Cyprus\": \"Cyprus\",\n",
    "\"Czech Republic\": \"Czech Republic\",\n",
    "\"Denmark\": \"Denmark\",\n",
    "\"Estonia\": \"Estonia\",\n",
    "\"Finland\": \"Finland\",\n",
    "\"France\": \"France\",\n",
    "\"Georgia\": \"Georgia\",\n",
    "\"Germany\": \"Germany\",\n",
    "\"Greece\": \"Greece\",\n",
    "\"Hungary\": \"Hungary\",\n",
    "\"Iceland\": \"Iceland\",\n",
    "\"Ireland\": \"Ireland\",\n",
    "\"Israel\": \"Israel\",\n",
    "\"Italy\": \"Italy\",\n",
    "\"Latvia\": \"Latvia\",\n",
    "\"Lithuania\": \"Lithuania\",\n",
    "\"Luxembourg\": \"Luxembourg\",\n",
    "\"Malta\": \"Malta\",\n",
    "\"Moldova\": \"Moldova\",\n",
    "\"Monaco\": \"Monaco\",\n",
    "\"Montenegro\": \"Montenegro\",\n",
    "\"Morocco\": \"Morocco\",\n",
    "\"Netherlands\": \"Netherlands\",\n",
    "\"Norway\": \"Norway\",\n",
    "\"Poland\": \"Poland\",\n",
    "\"Portugal\": \"Portugal\",\n",
    "\"Romania\": \"Romania\",\n",
    "\"Russia\": \"Russia\",\n",
    "\"San Marino\": \"San Marino\",\n",
    "\"Serbia\": \"Serbia\",\n",
    "\"Slovakia\": \"Slovakia\",\n",
    "\"Slovenia\": \"Slovenia\",\n",
    "\"Spain\": \"Spain\",\n",
    "\"Sweden\": \"Sweden\",\n",
    "\"Switzerland\": \"Switzerland\",\n",
    "\"Turkey\": \"Turkey\",\n",
    "\"Ukraine\": \"Ukraine\",\n",
    "\"Yugoslavia\": \"Yugoslavia\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the positions the countries achieved form files.\n",
    "files = os.listdir(\"realRankings\")\n",
    "realRankings = dict()\n",
    "for f in files:\n",
    "    year = f.split(\".\")[0]\n",
    "    semiFinal = False\n",
    "    realRankings[year] = dict()\n",
    "    for line in fileinput.input(\"realRankings/\"+f):\n",
    "        l = line.split(\",\")\n",
    "#         First line is a header\n",
    "        if fileinput.lineno() == 1:\n",
    "            continue\n",
    "#       If start with 'Country', line is a header and it is beginning to read the positions in the semi finals.\n",
    "        if l[0].startswith(\"Country\"):\n",
    "            semiFinal = True\n",
    "            continue\n",
    "#       If position is in semi-final, I only care about the fact that it did not reach the finals.\n",
    "        if semiFinal:\n",
    "            realRankings[year][l[0]] = (\"S\", l[2])\n",
    "        elif not semiFinal:\n",
    "            realRankings[year][l[0]] = l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 0: winner, position is 1.\n",
    "# Category 1: Top 3, position is 2 or 3.\n",
    "# Category 2: Top 5, position is 4 or 5.\n",
    "# Category 3: Top 10, position is between 6 and 10.\n",
    "# Category 4: In Final, position is higher than 10.\n",
    "# Category 5: Not in final, position is defined as 'S'.\n",
    "def inCategory0(year, country):\n",
    "    try:\n",
    "        position = int(realRankings[year][country])\n",
    "    except:\n",
    "        return False\n",
    "    if position == 1:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def inCategory1(year, country):\n",
    "    try:\n",
    "        position = int(realRankings[year][country])\n",
    "    except:\n",
    "        return False\n",
    "    if position <= 3:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def inCategory2(year, country):\n",
    "    try:\n",
    "        position = int(realRankings[year][country])\n",
    "    except:\n",
    "        return False\n",
    "    if position <= 5:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def inCategory3(year, country):\n",
    "    try:\n",
    "        position = int(realRankings[year][country])\n",
    "    except:\n",
    "        return False\n",
    "    if position <= 10:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def inCategory4(year, country):\n",
    "    try:\n",
    "        position = int(realRankings[year][country])\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def inCategory5(year, country):\n",
    "    position = realRankings[year][country][0]\n",
    "    if type(position) == str and position == \"S\":\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def getCategory(year, country):\n",
    "    if inCategory0(year, country):\n",
    "        return 0\n",
    "    elif inCategory1(year, country):\n",
    "        return 1\n",
    "    elif inCategory2(year, country):\n",
    "        return 2\n",
    "    elif inCategory3(year, country):\n",
    "        return 3\n",
    "    elif inCategory4(year, country):\n",
    "        return 4\n",
    "    elif inCategory5(year, country):\n",
    "        return 5\n",
    "\n",
    "# List of years in order, because dict.keys() always gives a random order.\n",
    "yearsInOrder = sorted(list(realRankings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function for trying to divide semi finals in a correct way, because the first place in a semi final is not \n",
    "# first place in the final as well.\n",
    "def getMaxFinalPositionAndMinSemi(year):\n",
    "    maxPos = -1\n",
    "    minPos = 44\n",
    "    for c in realRankings[year]:\n",
    "        if type(realRankings[year][c]) != tuple:\n",
    "#             Get lowest place of finale.\n",
    "            if int(realRankings[year][c]) > maxPos:\n",
    "                maxPos = int(realRankings[year][c])\n",
    "        elif type(realRankings[year][c]) == tuple:\n",
    "            if int(realRankings[year][c][1]) < minPos:\n",
    "                minPos = int(realRankings[year][c][1])\n",
    "    return maxPos, minPos\n",
    "  \n",
    "# Divide categorie per 20% quantile.\n",
    "quants = dict()\n",
    "nQuants = 5\n",
    "# Loop over years, skip 1956.\n",
    "for year in yearsInOrder[1:]:\n",
    "    quants[year] = dict()\n",
    "    qSize = int(len(realRankings[year])/nQuants)\n",
    "    toBeSorted = dict()\n",
    "#     For all the years with a semi-final, get max and min final positions in the semi-final relative to the\n",
    "#     final places.\n",
    "    if int(year) > 2003:\n",
    "        ma, mi = getMaxFinalPositionAndMinSemi(year)\n",
    "    for c in realRankings[year]:\n",
    "#         If country ended in a semi final, get a place below the final places, so a ranking that is complet is\n",
    "#         formed.\n",
    "        if type(realRankings[year][c]) == tuple:\n",
    "            toBeSorted[c] = ma+(int(realRankings[year][c][1]) - mi + 1)\n",
    "        else:\n",
    "            toBeSorted[c] = int(realRankings[year][c])\n",
    "    sortedPlaces = sorted(toBeSorted.items(), key=itemgetter(1))\n",
    "    sortedCountries = [cc[0] for cc in sortedPlaces]\n",
    "#     Divide in to the quantiles.\n",
    "    q = [sortedCountries[:qSize], sortedCountries[qSize:qSize*2], sortedCountries[qSize*2:qSize*3],\n",
    "         sortedCountries[qSize*3:qSize*4], sortedCountries[qSize*4:]]\n",
    "#     Declare which categories.\n",
    "    for i in range(len(q)):\n",
    "        for c in q[i]:\n",
    "            quants[year][c] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the jsons with all the audio features per year, per country, per segment.\n",
    "segmentedJsons = dict()\n",
    "for year in yearsInOrder:\n",
    "    segmentedJsons[year] = dict()\n",
    "    files = os.listdir(\"extractedFrames/\"+year)\n",
    "    for f in files:\n",
    "        country = f.split(\"_\")[1].split(\".\")[0]\n",
    "        with open(\"extractedFrames/\"+year+\"/\"+f) as ff:\n",
    "            segmentedJsons[year][country] = json.load(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eurovision_song_contest_1975_2019v3.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-117acf65ed8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read data set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eurovision_song_contest_1975_2019v3.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m new = votes.rename(columns={\"(semi-) final\": \"round\", \"Jury or Televoting\": \"Jury_or_Televoting\",\n\u001b[1;32m      4\u001b[0m                   \"From country\": \"from_country\", \"To country\": \"to_country\"})\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eurovision_song_contest_1975_2019v3.xlsx'"
     ]
    }
   ],
   "source": [
    "# Read data set.\n",
    "votes = pd.read_excel('eurovision_song_contest_1975_2019v3.xlsx')\n",
    "new = votes.rename(columns={\"(semi-) final\": \"round\", \"Jury or Televoting\": \"Jury_or_Televoting\",\n",
    "                  \"From country\": \"from_country\", \"To country\": \"to_country\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f7e9edbd72d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#     Get the jury votes for final and semi-final, get points received per country and put in a list of tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mjf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Year==@yy and Jury_or_Televoting=='J' and round=='f'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mjsf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Year==@yy and Jury_or_Televoting=='J' and (round=='sf1' or round=='sf2')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mjury\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpointsReceivedCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointsReceivedCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new' is not defined"
     ]
    }
   ],
   "source": [
    "# No correct names in the votes dataset.\n",
    "def getAnEqualName(n):\n",
    "    if n == \"Bosnia & Herzegovina\":\n",
    "        return \"Bosnia and Herzegovina\"\n",
    "    elif n == \"The Netherlands\":\n",
    "        return \"Netherlands\"\n",
    "    elif n == \"F.Y.R. Macedonia\":\n",
    "        return \"North Macedonia\"\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "# Count all points that one country got, since the data set consits of how many points one country gave to another\n",
    "# country.\n",
    "def pointsReceivedCounter(df):\n",
    "    counted = dict()\n",
    "    for i, r in df.iterrows():\n",
    "        if r['to_country'] not in counted.keys():\n",
    "            counted[r['to_country']] = r[-2] \n",
    "        else:\n",
    "            counted[r['to_country']] += r[-2] \n",
    "    return counted\n",
    "\n",
    "# To remove countries, that are in both lists.\n",
    "def removeIntersect(l1, l2):\n",
    "    l = []\n",
    "    k1 = [ll[0] for ll in l1]\n",
    "    for k2, v2 in l2:\n",
    "        if k2 not in k1:\n",
    "            l.append((k2, v2))\n",
    "        \n",
    "    return l\n",
    "\n",
    "jury = dict()\n",
    "tele = dict()\n",
    "# From 2016.\n",
    "for y in yearsInOrder[60:]:\n",
    "    yy = int(y)\n",
    "#     Get the jury votes for final and semi-final, get points received per country and put in a list of tuples.\n",
    "    jf = new.query(\"Year==@yy and Jury_or_Televoting=='J' and round=='f'\")\n",
    "    jsf = new.query(\"Year==@yy and Jury_or_Televoting=='J' and (round=='sf1' or round=='sf2')\")\n",
    "    jury[y] = (pointsReceivedCounter(jf), pointsReceivedCounter(jsf))\n",
    "#     Get the tele votes for final en semi-final, get points received per country and put in a list of tuples. \n",
    "    tf = new.query(\"Year==@yy and Jury_or_Televoting=='T' and round=='f'\")\n",
    "    tsf = new.query(\"Year==@yy and Jury_or_Televoting=='T' and (round=='sf1' or round=='sf2')\") \n",
    "    tele[y] = (pointsReceivedCounter(tf), pointsReceivedCounter(tsf))\n",
    "    \n",
    "for y in yearsInOrder[60:]:\n",
    "#     Sort jury and televots from most to least points\n",
    "    jury[y] = (sorted(jury[y][0].items(), key=itemgetter(1)), sorted(jury[y][1].items(), key=itemgetter(1)))\n",
    "    tele[y] = (sorted(tele[y][0].items(), key=itemgetter(1)), sorted(tele[y][1].items(), key=itemgetter(1)))\n",
    "    \n",
    "    jury[y][0].reverse()\n",
    "    jury[y][1].reverse()\n",
    "    tele[y][0].reverse()\n",
    "    tele[y][1].reverse()\n",
    "\n",
    "#     Remove the countries that are in both semi-final and final, those reached the final, they do not need\n",
    "#     to be in the lists twice.\n",
    "    jury[y][0].extend(removeIntersect(jury[y][0], jury[y][1]))\n",
    "    jury[y] = jury[y][0]\n",
    "    tele[y][0].extend(removeIntersect(tele[y][0], tele[y][1]))\n",
    "    tele[y] = tele[y][0]\n",
    "        \n",
    "quantsJ = dict()\n",
    "quantsT = dict()\n",
    "for year in yearsInOrder[60:]:\n",
    "    quantsJ[year] = dict()\n",
    "    quantsT[year] = dict()\n",
    "    \n",
    "#    Divide jury and tele votes according to the division of the first model. (winner, top 3, top 5, top 10 etc.)\n",
    "#    Since it is since 2016, the partition of semi-finals to final is consistent.\n",
    "    qJ = [jury[year][:1], jury[year][1:3], jury[year][3:5],\n",
    "         jury[year][5:10], jury[year][10:26], jury[year][26:]]\n",
    "\n",
    "    qT = [tele[year][:1], tele[year][1:3], tele[year][3:5],\n",
    "         tele[year][5:10], tele[year][10:26], tele[year][26:]]\n",
    "\n",
    "#     Declare belongling categories in a dictionary.\n",
    "    for i in range(len(qJ)):\n",
    "        for j in range(len(qJ[i])):\n",
    "            cJ = getAnEqualName(qJ[i][j][0])\n",
    "            cT = getAnEqualName(qT[i][j][0])\n",
    "            \n",
    "            quantsJ[year][cJ] = i\n",
    "            quantsT[year][cT] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To keep the columns in order.\n",
    "columns = [['onset_rate', 'danceability', 'bpm_histogram_second_peak_spread', 'beats_count', 'beats_loudness', 'bpm', \n",
    "            'bpm_histogram_first_peak_bpm', \n",
    "           'bpm_histogram_first_peak_weight', 'bpm_histogram_second_peak_bpm', 'bpm_histogram_second_peak_weight'], \n",
    "           ['melbands_flatness_db', 'erbbands_kurtosis', 'melbands_crest', 'pitch_salience', 'hfc', \n",
    "           'barkbands_kurtosis', 'barkbands_spread', 'spectral_energyband_low', 'dynamic_complexity', \n",
    "           'dissonance', 'spectral_skewness', 'average_loudness', 'spectral_rolloff', 'spectral_complexity', \n",
    "           'erbbands_flatness_db', 'erbbands_crest', 'silence_rate_60dB', \n",
    "           'barkbands_flatness_db', 'spectral_flux','erbbands_skewness', \n",
    "           'melbands_skewness', 'erbbands_spread', 'spectral_kurtosis', 'melbands_kurtosis', \n",
    "           'barkbands_crest', 'silence_rate_30dB', 'barkbands_skewness', 'spectral_spread',\n",
    "           'spectral_centroid', 'spectral_strongpeak', 'spectral_energyband_high', \n",
    "           'spectral_energyband_middle_high', 'spectral_energyband_middle_low', 'melbands_spread', 'spectral_rms',\n",
    "            'spectral_entropy', 'spectral_energy', 'zerocrossingrate'], \n",
    "           ['tuning_nontempered_energy_ratio','tuning_equal_tempered_deviation', 'tuning_diatonic_strength',\n",
    "           'chords_strength', 'chords_changes_rate', 'hpcp_entropy', 'hpcp_crest', 'chords_number_rate', \n",
    "           'tuning_frequency', 'chords_key', 'chords_scale']]\n",
    "main = [\"rhythm\", \"lowlevel\", \"tonal\"]\n",
    "# Dummy variables\n",
    "dummyForChordsKey = { 'C':0, 'C#':1, 'D#':2, 'D':3, 'Eb':4, 'E':5, 'F#':6, 'F':7,'G':8,\n",
    "                     'G#':9, 'Ab':10, 'A':11, 'A#':12,'Bb':13, 'B':14}\n",
    "dummyForChordsScale = {'major': 0, 'minor': 1}\n",
    "\n",
    "# Get the audio feature values, since itis defined in dicts with means and etc.\n",
    "def convertDataPerYear(year):\n",
    "    data = []\n",
    "    for countryN in segmentedJsons[year]:\n",
    "        entry = []\n",
    "#         Only the country name, not the segment number as well.\n",
    "        country = countryN[:-1]\n",
    "        for i, mainFeature in enumerate(main):\n",
    "            \n",
    "            for audioFeature in columns[i]:\n",
    "                value = segmentedJsons[year][countryN][mainFeature][audioFeature]\n",
    "                \n",
    "#                 Get the dummy value.\n",
    "                if audioFeature == \"chords_key\":\n",
    "                    entry.append(dummyForChordsKey[value])\n",
    "                    \n",
    "                elif audioFeature == \"chords_scale\":\n",
    "                    entry.append(dummyForChordsScale[value])\n",
    "#               If the audio feature contains a dict with mean, stdev, max, min, etc, get the mean value.\n",
    "                elif type(value) == dict and \"mean\" in value:\n",
    "                    entry.append(value[\"mean\"])\n",
    "#                 If the audio feature is an int or float.    \n",
    "                elif type(value) == int or type(value) == float:\n",
    "                    entry.append(value)\n",
    "#          Also add the category and country+segment(id) in to the dict. Comment according to your needs.\n",
    "\n",
    "#         Oneven model\n",
    "        entry.append(getCategory(year, landNameConverter[country]))\n",
    "    \n",
    "#     Even model\n",
    "#         entry.append(quants[year][landNameConverter[country]])\n",
    "\n",
    "#    Oneven Jury model\n",
    "#         entry.append(quantsJ[year][landNameConverter[country]])\n",
    "\n",
    "#   Oneven Tele model\n",
    "#         entry.append(quantsT[year][landNameConverter[country]])\n",
    "\n",
    "        entry.append(year+\"_\"+countryN)\n",
    "        data.append(entry)\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Get audio features for multiple years.\n",
    "def doAConvertForMultiYears(years):\n",
    "    d = []\n",
    "    for y in years:\n",
    "        data = convertDataPerYear(y)\n",
    "        d.extend(data)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Flatten the columns for dataFraming the data.\n",
    "audioFeatures = [item for sublist in columns for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if document is relevent according to given query.\n",
    "def isRelevant(document, query):\n",
    "    if document['trueCat'] <= query:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Calculate average precision with a given query.\n",
    "def AP(rank, query):\n",
    "    ap = 0\n",
    "    counter = 0\n",
    "    for i in range(len(rank)):\n",
    "        if isRelevant(rank.iloc[i], query):\n",
    "            denominator = i + 1\n",
    "            counter += 1\n",
    "            ap += (counter/denominator)\n",
    "    return ap/counter\n",
    "\n",
    "# Get a full ranking with a soft class. The mean of all the predicted categories according to their probabilities.\n",
    "def getAFullRankingFromPredictionsSoftClass(data, predictionsDataFrame):\n",
    "    rankFrame = dict()\n",
    "    for i, row in predictionsDataFrame.iterrows():\n",
    "#         Determine soft class.\n",
    "        softclass = (row['p0']*0) + (row['p1']*1)+(row['p2']*2) + (row['p3']*3)+(row['p4']*4) + (row['p5']*5)\n",
    "#     Store in dictionary and convert to dataframe.\n",
    "        rankFrame[i] = [data.iloc[i][\"id\"], softclass, row[\"predict\"], data.iloc[i][\"category\"]]\n",
    "    return pd.DataFrame.from_dict(rankFrame, orient='index', columns=[\"id\",\"softCat\", \"hardCat\", \"trueCat\"])\n",
    "\n",
    "# Get a full ranking with latent variables.\n",
    "def getAFullRankingFromPredictionsLatent(data, predictionsDataFrame, coefs):\n",
    "    rankFrame = dict()\n",
    "    for i, row in data.iterrows():\n",
    "#         Determine latent variable.\n",
    "        latent = np.dot(np.array(row[:-2].tolist()), np.array(coefs.tolist()))\n",
    "#     Store in dictionary and convert to dataframe.\n",
    "        rankFrame[i] = [row[\"id\"], latent, predictionsDataFrame.iloc[i][\"predict\"], row[\"category\"]]\n",
    "    return pd.DataFrame.from_dict(rankFrame, orient='index', columns=[\"id\",\"softCat\", \"hardCat\", \"trueCat\"])\n",
    "\n",
    "# Get one segment per song by selecting the highest placed segment.\n",
    "def getRankWithBestSegments(rank):\n",
    "    mins = dict()\n",
    "    for i, row in rank.iterrows():\n",
    "        year, segment = row[\"id\"].split(\"_\")\n",
    "        country = segment[:-1]\n",
    "        idd = year+\"_\"+country\n",
    "        if idd in list(mins.keys()):\n",
    "#             Find for one country highest placing.\n",
    "            if mins[idd][\"softCat\"] > row[\"softCat\"]:\n",
    "                mins[idd] = row.to_dict()\n",
    "        else:\n",
    "            mins[idd] = row.to_dict()\n",
    "    forFrame = dict()\n",
    "#     Prepare data to be in a frame.\n",
    "    for k in mins:\n",
    "        forFrame[k] = list(mins[k].values())\n",
    "#    Make data frame and sort to a full ranking.\n",
    "    minFrame = pd.DataFrame.from_dict(forFrame, orient='index', columns=list(row.to_dict().keys()))\n",
    "    minFrame.sort_values([\"softCat\"], inplace=True)\n",
    "    return minFrame\n",
    "\n",
    "# Make a confusion matrix for predicitions of model.\n",
    "def confusionMatrix(predictions, test):\n",
    "    matrix = [[0 for _ in range(6)] for _ in range(6)]\n",
    "    accuracyVector = [0 for _ in range(6)]\n",
    "    for i, row in predictions.iterrows():\n",
    "        t = int(test.iloc[i]['category'])\n",
    "        p = int(row['predict'] )\n",
    "        matrix[t][p] += 1\n",
    "#         Return the matrix and the sums of predictions and trues.\n",
    "    return matrix, np.sum(matrix, axis=1), np.sum(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ordinal model for predicting categories.\n",
    "def getOrdinalModel(train, valid, test, audioFeatures):\n",
    "#     Set the category value as target value, to predict.\n",
    "    train['target'] = train['category'].asfactor()\n",
    "    valid['target'] = valid['category'].asfactor()\n",
    "    test['target'] = test['category'].asfactor()\n",
    "\n",
    "    #     Define model\n",
    "    model = H2OGeneralizedLinearEstimator(standardize = True,\n",
    "                                          family='ordinal',\n",
    "                                          solver='GRADIENT_DESCENT_SQERR',\n",
    "                                          nfolds=4)\n",
    "    \n",
    "    # Parameters to find the best model. 0.4 is more rigid regression than lasso.\n",
    "    hyperParams = {'alpha': np.arange(0,1.1, 0.1).tolist()}\n",
    "    \n",
    "#     Get best model.\n",
    "    griddedModel = H2OGridSearch(model=model, hyper_params=hyperParams)\n",
    "    \n",
    "#     Train model with train and validation data.\n",
    "    griddedModel.train(x=audioFeatures, y=\"target\", training_frame=train, validation_frame=valid)\n",
    "    bestModel = griddedModel.get_grid(sort_by=\"MSE\")[0]\n",
    "    \n",
    "    return bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years to make a model from and predict the last year of the sequence. frto[0] is a model based on all years,\n",
    "# exluding 1956, to predict 2019. frto[1:7] is per 10 years, starting with 1957. Not all are consistently 10 years.\n",
    "# frto[7:] is, what I tought, music era's. In this case: 60's, 70's, 80's, 90's, 00's and 10's.\n",
    "frto = [[1,64],[1,12],[12,22],[22,32],[32,42],[42,52],[52,63],[4,13],[14,23],[24,33],[34,43],[44,53],[54,63]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.6\" 2020-01-14; OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1); OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
      "  Starting server from /home/hester/.local/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpw0osbebg\n",
      "  JVM stdout: /tmp/tmpw0osbebg/h2o_hester_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpw0osbebg/h2o_hester_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Amsterdam</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 13 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_hester_b7gxwt</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.848 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.9 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster timezone:       Europe/Amsterdam\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.1\n",
       "H2O cluster version age:    1 month and 13 days\n",
       "H2O cluster name:           H2O_from_python_hester_b7gxwt\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.848 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.6.9 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get connection with h2o server.\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm Grid Build progress: |████████████████████████████████████████████████| 100%\n",
      "Intercepts:\n",
      "std_coefs_class_0    -2.21064\n",
      "std_coefs_class_1    -1.61883\n",
      "std_coefs_class_2   -0.876736\n",
      "std_coefs_class_3    -0.36469\n",
      "std_coefs_class_4      1.0866\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "spectral_energyband_low  =  -0.30647996044650283\n",
      "erbbands_flatness_db  =  0.2534743172719919\n",
      "beats_loudness  =  -0.23396771786553702\n",
      "spectral_energy  =  -0.23355569713604543\n",
      "tuning_frequency  =  0.22583105006581333\n",
      "dissonance  =  -0.2086690181434792\n",
      "spectral_flux  =  -0.20381295779746236\n",
      "tuning_nontempered_energy_ratio  =  -0.20369624229378405\n",
      "erbbands_spread  =  -0.2003986989565729\n",
      "tuning_equal_tempered_deviation  =  -0.19994003809776292\n",
      "barkbands_spread  =  -0.19281414630345603\n",
      "spectral_entropy  =  -0.19076559654562864\n",
      "spectral_rms  =  -0.18562488585098963\n",
      "melbands_skewness  =  -0.18339130443879448\n",
      "spectral_kurtosis  =  0.18024420867107313\n",
      "barkbands_flatness_db  =  0.17557969326849557\n",
      "silence_rate_30dB  =  0.17170709014763402\n",
      "spectral_energyband_high  =  -0.15939567410082187\n",
      "pitch_salience  =  0.1587171771285343\n",
      "melbands_crest  =  -0.15643882138414883\n",
      "hfc  =  -0.14977733918606206\n",
      "spectral_strongpeak  =  0.13266155484278233\n",
      "erbbands_crest  =  0.11215148588597401\n",
      "chords_changes_rate  =  -0.10261215238784521\n",
      "hpcp_entropy  =  -0.10227092173953285\n",
      "erbbands_kurtosis  =  0.10059170483571402\n",
      "hpcp_crest  =  0.09639651665692435\n",
      "spectral_skewness  =  0.0893430181967111\n",
      "spectral_complexity  =  -0.089155688316986\n",
      "barkbands_skewness  =  -0.08801755137076357\n",
      "spectral_energyband_middle_low  =  0.08761251312484579\n",
      "tuning_diatonic_strength  =  0.08547380247808498\n",
      "onset_rate  =  -0.08234018293405208\n",
      "melbands_flatness_db  =  0.07347765912162631\n",
      "chords_number_rate  =  -0.0716134324026567\n",
      "silence_rate_60dB  =  0.07041860962083028\n",
      "chords_scale  =  -0.06509730792696299\n",
      "dynamic_complexity  =  0.053076453298555704\n",
      "spectral_energyband_middle_high  =  -0.051035656937674444\n",
      "bpm_histogram_second_peak_weight  =  0.04547074448345143\n",
      "barkbands_crest  =  -0.04122964718532029\n",
      "bpm_histogram_first_peak_weight  =  0.039667572765310806\n",
      "erbbands_skewness  =  0.0377113990095219\n",
      "spectral_spread  =  -0.03579454715568627\n",
      "spectral_rolloff  =  0.02639172380266018\n",
      "average_loudness  =  -0.024847220117107906\n",
      "melbands_kurtosis  =  -0.023637480891830525\n",
      "chords_strength  =  0.014279870700180497\n",
      "chords_key  =  0.013446138349604215\n",
      "bpm_histogram_first_peak_bpm  =  0.013058341219766295\n",
      "bpm  =  0.011095142100564276\n",
      "beats_count  =  0.009819073407743009\n",
      "barkbands_kurtosis  =  -0.008968719315523132\n",
      "spectral_centroid  =  0.005620548568410616\n",
      "bpm_histogram_second_peak_bpm  =  0.0041812544213409505\n",
      "zerocrossingrate  =  -0.001896366470945297\n",
      "danceability  =  -0.001158052059682023\n",
      "melbands_spread  =  0.0010350426156880718\n",
      "bpm_histogram_second_peak_spread  =  -0.0007085788774701673\n",
      "\n",
      "\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Predicting categories.\n",
    "\n",
    "# Get the flat columns and add category and id for dataframing the data.\n",
    "flatColumns = [item for sublist in columns for item in sublist]\n",
    "flatColumns.append(\"category\")\n",
    "flatColumns.append(\"id\")\n",
    "\n",
    "# Loop over fr to's. But only get the first element in list, That are all years of the song contest.\n",
    "for fr, to in frto[:1]:\n",
    "#     Get the audio feature values for the years that make the model.\n",
    "\n",
    "#     Uncomment when using jury or tele votes\n",
    "#     dataList = doAConvertForMultiYears(yearsInOrder[60:])\n",
    "\n",
    "    dataList = doAConvertForMultiYears(yearsInOrder[fr:to])\n",
    "\n",
    "    \n",
    "    dataH2OFrame = h2o.H2OFrame(pd.DataFrame(dataList, columns=flatColumns))\n",
    "    \n",
    "#     Devide the data in to train, valid and test, with 69%, 16% and 15%. seed=1 is for reproduction.\n",
    "    train, valid, test = dataH2OFrame.split_frame(ratios=[0.69,0.16], seed=1)\n",
    "    model = getOrdinalModel(train, valid, test, audioFeatures)\n",
    "\n",
    "#   ==============================================================================================\n",
    "#   Intercepts\n",
    "#      Print the standardized intercepts of the model.\n",
    "#   ==============================================================================================\n",
    "    print(\"Intercepts:\")\n",
    "    print(model._model_json['output']['coefficients_table'].as_data_frame().iloc[0][['std_coefs_class_0',\n",
    "                                                                                   'std_coefs_class_1',\n",
    "                                                                                   'std_coefs_class_2',\n",
    "                                                                                   'std_coefs_class_3',\n",
    "                                                                                   'std_coefs_class_4']])\n",
    "    print(\"\\n\")\n",
    "#   ==============================================================================================\n",
    "#   Selected coefficients\n",
    "#       Print the standardized values of the model. This shows the, by normalization, selected \n",
    "#       audio features.\n",
    "#   ==============================================================================================\n",
    "    print(\"Coefficients:\")\n",
    "    selectedCoefs = model._model_json['output']['coefficients_table'].as_data_frame()[['names',     \n",
    "                                                                                       'std_coefs_class_0']].iloc[1:]\n",
    "#     Sort the selected coefficients for absolute values. Therefor the values first need to be absolute, then \n",
    "#     signs need to be put back, because those are important.\n",
    "    selection = dict()\n",
    "#     Loop over coefficients.\n",
    "    for i, r in selectedCoefs.iterrows():\n",
    "#         Get the absolute value and put in temporary dictionary.\n",
    "        selection[i] = abs(r['std_coefs_class_0'])\n",
    "#     Sort the selection in descending order.\n",
    "    sortedSelection = sorted(selection.items(), key=itemgetter(1))\n",
    "    sortedSelection.reverse()\n",
    "#     Loop over the sorted selection, get the real value from the original coefficients and print them in \n",
    "#     order.\n",
    "    for i, c in sortedSelection:\n",
    "        print(selectedCoefs.iloc[i-1]['names'], \" = \", selectedCoefs.iloc[i-1]['std_coefs_class_0'])\n",
    "    print(\"\\n\")\n",
    "#   ==============================================================================================\n",
    "    \n",
    "#     Make the prediction with the fetched model, to calculate accuracies. Exclude the id and category.\n",
    "\n",
    "    predictions = model.predict(test[:,:-2])\n",
    "    predictieDataFrame = predictions.as_data_frame()\n",
    "    dataFrameToPred = test.as_data_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15, 5, 7, 8, 12, 13], [20, 13, 16, 6, 18, 18], [32, 13, 10, 2, 11, 24], [73, 24, 28, 25, 28, 63], [108, 50, 78, 42, 124, 165], [14, 4, 7, 7, 25, 141]] [ 60  91  92 241 567 198] [262 109 146  90 218 424]\n",
      "recalls: 15 / 60 0.25\n",
      "precisions: 15 / 262 0.05725190839694656\n",
      "accuracies: 15 / 307 0.048859934853420196\n",
      "recalls: 53 / 151 0.3509933774834437\n",
      "precisions: 53 / 371 0.14285714285714285\n",
      "accuracies: 53 / 469 0.11300639658848614\n",
      "recalls: 131 / 243 0.5390946502057613\n",
      "precisions: 131 / 517 0.25338491295938104\n",
      "accuracies: 131 / 629 0.2082670906200318\n",
      "recalls: 297 / 484 0.6136363636363636\n",
      "precisions: 297 / 607 0.48929159802306427\n",
      "accuracies: 297 / 794 0.37405541561712846\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "[0.20713781 0.25410075 0.34065888 0.5548895 ]\n"
     ]
    }
   ],
   "source": [
    "# Predictions for the model\n",
    "\n",
    "#   ==============================================================================================\n",
    "#    Confusion Matrix\n",
    "#       Print the confusion matrix. (is not pprint)\n",
    "#   ==============================================================================================\n",
    "matrix, totalsTrues, totalsPredicts = confusionMatrix(predictieDataFrame, dataFrameToPred)\n",
    "print(matrix, totalsTrues, totalsPredicts)\n",
    "#   ==============================================================================================\n",
    "#    Accuracy, Precision, Recall\n",
    "#      For all categories that matter, compute accuracy, precision and recall and print.\n",
    "#   ==============================================================================================\n",
    "accs = [0 for _ in range(4)]\n",
    "precisions = [0 for _ in range(4)]\n",
    "recalls = [0 for _ in range(4)]\n",
    "\n",
    "# Loop over categories in question.\n",
    "for p in range(4):\n",
    "#     Loop over confusion matrix till category.\n",
    "    for i in range(p+1):\n",
    "#         Loop again over confusion matrix till category.\n",
    "        for j in range(p+1):\n",
    "#         Get recall, precision and accuracies.\n",
    "            recalls[p] += matrix[i][j]\n",
    "            precisions[p] += matrix[i][j]\n",
    "            accs[p] += matrix[i][j]\n",
    "#   Print.\n",
    "    print(\"Problem:\", p)\n",
    "    print(\"recalls:\",  recalls[p], \"/\", sum(totalsTrues[:p+1]), recalls[p]/  sum(totalsTrues[:p+1]))\n",
    "    print(\"precisions:\", precisions[p], \"/\", sum(totalsPredicts[:p+1]), \n",
    "          precisions[p]/  sum(totalsPredicts[:p+1]))\n",
    "    print(\"accuracies:\", accs[p], \"/\", sum(totalsPredicts[:p+1])+sum(totalsTrues[:p+1]) - accs[p], \n",
    "          accs[p]/(sum(totalsPredicts[:p+1])+sum(totalsTrues[:p+1]) - accs[p]))\n",
    "    \n",
    "#   ==============================================================================================\n",
    "#    Mean Average Precision Score\n",
    "#       Compute MAP for full rankings and print.\n",
    "#   ==============================================================================================\n",
    "\n",
    "APs = [[] for _ in range(4)]\n",
    "# Loop over all years, skip 1956.\n",
    "for y in yearsInOrder[1:]:\n",
    "#     Get data and put in h2o frame.\n",
    "    dataList = convertDataPerYear(y)\n",
    "    dataH2OFrame = h2o.H2OFrame(pd.DataFrame(dataList, columns=flatColumns))\n",
    "    \n",
    "#   Get predictions. (These are different form before.)\n",
    "    predictions = model.predict(dataH2OFrame[:,:-2])\n",
    "    predictieDataFrame = predictions.as_data_frame()\n",
    "    dataFrameToPred = dataH2OFrame.as_data_frame()\n",
    "    \n",
    "#   Get full predicted rank from predictions, with a soft class or with the latent variable.\n",
    "#   If the latent variable shows really weird values, I advice to use the soft class one.\n",
    "#     rank = getAFullRankingFromPredictionsLatent(dataFrameToPred, predictieDataFrame, \n",
    "#                                                 selectedCoefs[\"std_coefs_class_0\"])\n",
    "    rank = getAFullRankingFromPredictionsSoftClass(dataFrameToPred, predictieDataFrame)\n",
    "    filterRank = getRankWithBestSegments(rank)\n",
    "\n",
    "#     Uncomment this if you want to see all the full ranking predicitions.\n",
    "#     print(filterRank[\"id\"])\n",
    "\n",
    "#   Call the AP function to get the Average Precisions for one year.\n",
    "#   Loop over the categories that matter, categories 0 till 3.\n",
    "    for p in range(4):\n",
    "        ap = AP(filterRank, p)\n",
    "        APs[p].append(ap)\n",
    "\n",
    "# Get the mean of the AP's per year, that gives 4 MAP's.\n",
    "print(\"MAPS:\", np.mean(APs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
